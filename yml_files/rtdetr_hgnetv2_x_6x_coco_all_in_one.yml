# 以下是rtdetr_hgnetv2_x_6x_coco.yml的内容

_BASE_: [
  '../datasets/coco_detection.yml',
  '../runtime.yml',
  '_base_/optimizer_6x.yml',
  '_base_/rtdetr_r50vd.yml',
  '_base_/rtdetr_reader.yml',
]

weights: output/rtdetr_hgnetv2_l_6x_coco/model_final
pretrain_weights: https://bj.bcebos.com/v1/paddledet/models/pretrained/PPHGNetV2_X_ssld_pretrained.pdparams
find_unused_parameters: True
log_iter: 20



DETR:
  backbone: PPHGNetV2


PPHGNetV2:
  arch: 'X'
  return_idx: [1, 2, 3]
  freeze_stem_only: True
  freeze_at: 0
  freeze_norm: True
  lr_mult_list: [0., 0.01, 0.01, 0.01, 0.01]


HybridEncoder:
  hidden_dim: 384
  use_encoder_idx: [2]
  num_encoder_layers: 1
  encoder_layer:
    name: TransformerLayer
    d_model: 384
    nhead: 8
    dim_feedforward: 2048
    dropout: 0.
    activation: 'gelu'
  expansion: 1.0

# 以下是coco_detection.yml的内容
metric: COCO
num_classes: 4

TrainDataset:
  name: COCODataSet
  image_dir: train/JPEGImages
  anno_path: train/voc_train.json
  dataset_dir: /home/aistudio/PaddleDetection2.5/dataset/coco
  data_fields: ['image', 'gt_bbox', 'gt_class', 'is_crowd']

EvalDataset:
  name: COCODataSet
  image_dir: train/JPEGImages
  anno_path: train/voc_val.json
  dataset_dir: /home/aistudio/PaddleDetection2.5/dataset/coco
  allow_empty: true

TestDataset:
  name: ImageFolder
  anno_path: train/voc_val.json # also support txt (like VOC's label_list.txt)
  dataset_dir: /home/aistudio/PaddleDetection2.5/dataset/coco # if set, anno_path will be 'dataset_dir/anno_path'


# 以下是runtime.yml的内容
use_gpu: true
use_xpu: false
use_mlu: false
use_npu: false
log_iter: 20
save_dir: output
snapshot_epoch: 9
print_flops: false
print_params: false

# Exporting the model
export:
  post_process: True  # Whether post-processing is included in the network when export model.
  nms: True           # Whether NMS is included in the network when export model.
  benchmark: False    # It is used to testing model performance, if set `True`, post-process and NMS will not be exported.
  fuse_conv_bn: False


# 以下是optimizer_6x.yml的内容
epoch: 144

LearningRate:
  base_lr: 0.0001
  schedulers:
  - !PiecewiseDecay
    gamma: 1.0
    milestones: [100]
    use_warmup: true
  - !LinearWarmup
    start_factor: 0.001
    steps: 1500

OptimizerBuilder:
  clip_grad_by_norm: 0.1
  regularizer: false
  optimizer:
    type: AdamW
    weight_decay: 0.0001


这是一个关于学习率（Learning Rate）的配置片段，其中包含了学习率的初始设置、调度器以及线性预热的配置信息。

下面是对每个配置项的详细解释：

epoch: 60：总训练周期数，表示训练将运行60个周期。

LearningRate：学习率的配置信息。

base_lr: 0.001：学习率的初始值，设置为0.001。

schedulers：学习率调度器的列表，用于根据训练的进程调整学习率。

!PiecewiseDecay：使用 PiecewiseDecay 调度器。

gamma: 0.1：学习率衰减因子，表示每个里程碑（milestone）处学习率衰减为原来的0.1倍。

milestones: [8, 11]：里程碑的列表，表示在第8和第11个周期时进行学习率衰减。

!LinearWarmup：使用 LinearWarmup 预热调度器。

start_factor: 0.1：预热的初始学习率因子，表示预热时学习率为初始学习率的0.1倍。

steps: 1000：预热的步数，表示在前1000个步骤内进行线性预热，逐渐增加学习率到正常值。

这些配置项可以根据具体的训练需求进行调整，包括总训练周期数、初始学习率、调度器的选择和调参，以及预热的配置。学习率的调整策略对于训练的收敛和性能具有重要影响，需要根据具体问题和实验经验进行选择和调整。

# 以下是rtdetr_r50vd.yml的内容
architecture: DETR
pretrain_weights: https://paddledet.bj.bcebos.com/models/pretrained/ResNet50_vd_ssld_v2_pretrained.pdparams
norm_type: sync_bn
use_ema: True
ema_decay: 0.9999
ema_decay_type: "exponential"
ema_filter_no_grad: True
hidden_dim: 256
use_focal_loss: True
eval_size: [640, 640]


DETR:
  backbone: ResNet
  neck: HybridEncoder
  transformer: RTDETRTransformer
  detr_head: DINOHead
  post_process: DETRPostProcess

ResNet:
  # index 0 stands for res2
  depth: 50
  variant: d
  norm_type: bn
  freeze_at: 0
  return_idx: [1, 2, 3]
  lr_mult_list: [0.1, 0.1, 0.1, 0.1]
  num_stages: 4
  freeze_stem_only: True

HybridEncoder:
  hidden_dim: 256
  use_encoder_idx: [2]
  num_encoder_layers: 1
  encoder_layer:
    name: TransformerLayer
    d_model: 256
    nhead: 8
    dim_feedforward: 1024
    dropout: 0.
    activation: 'gelu'
  expansion: 1.0


RTDETRTransformer:
  num_queries: 300
  position_embed_type: sine
  feat_strides: [8, 16, 32]
  num_levels: 3
  nhead: 8
  num_decoder_layers: 6
  dim_feedforward: 1024
  dropout: 0.0
  activation: relu
  num_denoising: 100
  label_noise_ratio: 0.5
  box_noise_scale: 1.0
  learnt_init_query: False

DINOHead:
  loss:
    name: DINOLoss
    loss_coeff: {class: 1, bbox: 5, giou: 2}
    aux_loss: True
    use_vfl: True
    matcher:
      name: HungarianMatcher
      matcher_coeff: {class: 2, bbox: 5, giou: 2}

DETRPostProcess:
  num_top_queries: 300


# 以下是rtdetr_reader.yml的内容
worker_num: 4
TrainReader:
  sample_transforms:
    - Decode: {}
    - RandomDistort: {prob: 0.8}
    - RandomExpand: {fill_value: [123.675, 116.28, 103.53]}
    - RandomCrop: {prob: 0.8}
    - RandomFlip: {}
  batch_transforms:
    - BatchRandomResize: {target_size: [480, 512, 544, 576, 608, 640, 640, 640, 672, 704, 736, 768, 800], random_size: True, random_interp: True, keep_ratio: False}
    - NormalizeImage: {mean: [0., 0., 0.], std: [1., 1., 1.], norm_type: none}
    - NormalizeBox: {}
    - BboxXYXY2XYWH: {}
    - Permute: {}
  batch_size: 4
  shuffle: true
  drop_last: true
  collate_batch: false
  use_shared_memory: false


EvalReader:
  sample_transforms:
    - Decode: {}
    - Resize: {target_size: [640, 640], keep_ratio: False, interp: 2}
    - NormalizeImage: {mean: [0., 0., 0.], std: [1., 1., 1.], norm_type: none}
    - Permute: {}
  batch_size: 4
  shuffle: false
  drop_last: false


TestReader:
  inputs_def:
    image_shape: [3, 640, 640]
  sample_transforms:
    - Decode: {}
    - Resize: {target_size: [640, 640], keep_ratio: False, interp: 2}
    - NormalizeImage: {mean: [0., 0., 0.], std: [1., 1., 1.], norm_type: none}
    - Permute: {}
  batch_size: 1
  shuffle: false
  drop_last: false


